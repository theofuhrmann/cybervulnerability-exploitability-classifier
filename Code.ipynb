{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3o-M0yX2RNl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, learning_curve, cross_validate\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as imbPipeline\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml1vKybp2VH7",
        "outputId": "4bdc5286-6591-44d6-c8d5-63cf8e04bf9d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akNMshUM2YdL"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Uni/TFG/Code/data/all_cves.json') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "JD7XW1023kgg",
        "outputId": "dc55d3c9-fa13-40d3-9e26-631c7bec800c"
      },
      "outputs": [],
      "source": [
        "df = pd.json_normalize(data)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v77pZGnSFsQ"
      },
      "outputs": [],
      "source": [
        "df.drop(df.iloc[:, -8:], axis=1, inplace=True)\n",
        "df.drop(df.iloc[:, -23:-1], axis=1, inplace=True)\n",
        "df.drop(df.iloc[:, -3:-2], axis=1, inplace=True)\n",
        "df.drop(df.iloc[:, -10:-7], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIRTh_QP3tF7"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={\n",
        "    'cve.CVE_data_meta.ID': 'id',\n",
        "    'cve.CVE_data_meta.ASSIGNER': 'assigner',\n",
        "    'cve.problemtype.problemtype_data': 'cwes',\n",
        "    'cve.references.reference_data': 'references',\n",
        "    'cve.description.description_data': 'description',\n",
        "    'configurations.nodes': 'cpes',\n",
        "    'impact.baseMetricV2.cvssV2.baseScore': 'score',\n",
        "    }, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jke4Kblt3wDv",
        "outputId": "7a6836ef-6cd7-47d6-896e-eeef243c9a46"
      },
      "outputs": [],
      "source": [
        "lang = {}\n",
        "for d in df['description']:\n",
        "    l = d[0]['lang']\n",
        "    if l in lang: lang[l] += 1\n",
        "    else: lang[l] = 0\n",
        "\n",
        "print(lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO_uaGtk3yFJ",
        "outputId": "3438d99e-00e8-449c-d5aa-d34209d9a971"
      },
      "outputs": [],
      "source": [
        "tags = []\n",
        "for refs in df['references'][:10]:\n",
        "    for ref in refs:\n",
        "        for tag in ref['tags']:\n",
        "            if not tag in tags:\n",
        "                tags.append(tag)\n",
        "print(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScCy1sjc30Ds"
      },
      "outputs": [],
      "source": [
        "def find_cwes(problemtype_data):\n",
        "    cwes = []\n",
        "    for p in problemtype_data:\n",
        "        for cwe in p['description']:\n",
        "            cwes.append(cwe['value'])\n",
        "            \n",
        "    return cwes\n",
        "\n",
        "def find_refs(references):\n",
        "    refs = []\n",
        "    for ref in references:\n",
        "        refs.append(ref['url'])\n",
        "    \n",
        "    return refs\n",
        "\n",
        "def find_exploit(references):\n",
        "    for ref in references:\n",
        "        if 'Exploit' in ref['tags']:\n",
        "            return 1                \n",
        "    return 0\n",
        "\n",
        "def find_num_cpes(nodes):\n",
        "    total = 0\n",
        "    for node in nodes:\n",
        "        if node['operator'] == 'AND':\n",
        "            total += find_num_cpes(node['children'])\n",
        "        else:\n",
        "            total += len(node['cpe_match'])\n",
        "    return total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SumwcNlr313v"
      },
      "outputs": [],
      "source": [
        "df_pre_cwes = list(df['cwes'].apply(lambda x: find_cwes(x)))\n",
        "df_pre_description = list(df['description'].apply(lambda x: x[0]['value']))\n",
        "df_pre_references = list(df['references'].apply(lambda x: find_refs(x)))\n",
        "df_pre_hasExploit = list(df['references'].apply(lambda x: find_exploit(x)))\n",
        "\n",
        "df_pre_publishedDate = pd.to_datetime(df['publishedDate'])\n",
        "df_pre_lastModifiedDate = pd.to_datetime(df['lastModifiedDate'])\n",
        "df_pre_dayDifference = (df_pre_lastModifiedDate - df_pre_publishedDate).dt.days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBzEbyYA35cj"
      },
      "outputs": [],
      "source": [
        "df_pre_numReferences = list(df['references'].apply(lambda x: len(x)))\n",
        "df_pre_descriptionLength = list(map(lambda x: len(x), df_pre_description))\n",
        "df_pre_numCPEs = list(df['cpes'].apply(lambda x: find_num_cpes(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNIGe_o4393k"
      },
      "outputs": [],
      "source": [
        "df_pre = pd.DataFrame(\n",
        "    list(zip(\n",
        "        df_pre_hasExploit,\n",
        "        df_pre_publishedDate, \n",
        "        df_pre_lastModifiedDate,\n",
        "        df_pre_dayDifference,\n",
        "        df_pre_descriptionLength,\n",
        "        df_pre_numCPEs,\n",
        "        df_pre_numReferences,\n",
        "        df_pre_cwes,\n",
        "        df_pre_description,\n",
        "        df_pre_references,\n",
        "        list(df['assigner']),\n",
        "        df.score)),\n",
        "    columns=[\n",
        "        'hasExploit',\n",
        "        'publishedDate',\n",
        "        'lastModifiedDate',\n",
        "        'dayDifference',\n",
        "        'descriptionLength',\n",
        "        'numCPEs',\n",
        "        'numReferences',\n",
        "        'cwes',\n",
        "        'description',\n",
        "        'references',\n",
        "        'assigner',\n",
        "        'score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ExV3AgIdnUO5",
        "outputId": "c3ebd0cb-5461-4cc9-9a97-baa45b6a5c69"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [10, 7]\n",
        "\n",
        "sns.histplot(x = df_pre[df_pre.hasExploit == True].score,\n",
        "             bins=20, color='seagreen')\n",
        "\n",
        "plt.title('CVSS scoring distribution of exploited vulnerabilites')\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Aggregated count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "7umuBwJDmDHv",
        "outputId": "538af569-f143-43d0-b5f9-0f4c39d13796"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [10, 7]\n",
        "\n",
        "sns.histplot(x = df_pre[df_pre.hasExploit == False].score,\n",
        "             bins=20, color='lightcoral')\n",
        "\n",
        "plt.title('CVSS scoring distribution of non exploited vulnerabilites')\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Aggregated count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8BKNsH3en2s",
        "outputId": "85e3663e-829c-4407-df47-4f764d3c807e"
      },
      "outputs": [],
      "source": [
        "print(\"accuracy\")\n",
        "print((len(df_pre[(df_pre.hasExploit == True) & (df_pre.score >= 5)]) + \n",
        "       len(df_pre[(df_pre.hasExploit == False) & (df_pre.score < 5)])) / len((df_pre)))\n",
        "\n",
        "print(\"precision of exploited vulnerabilites\")\n",
        "pre_ex = len(df_pre[(df_pre.hasExploit == True) & (df_pre.score >= 5)]) / len((df_pre.score >= 5))\n",
        "print(pre_ex)\n",
        "\n",
        "print(\"precision of non exploited vulnerabilities\")\n",
        "pre_non_ex = len(df_pre[(df_pre.hasExploit == False) & (df_pre.score < 5)]) / len((df_pre.score < 5))\n",
        "print(pre_non_ex)\n",
        "\n",
        "print(\"recall of exploited vulnerabilites\")\n",
        "rec_ex = len(df_pre[(df_pre.hasExploit == True) & (df_pre.score >= 5)]) / len(df_pre[df_pre.hasExploit == True])\n",
        "print(rec_ex)\n",
        "\n",
        "print(\"recall of non exploited vulnerabilites\")\n",
        "rec_non_ex = len(df_pre[(df_pre.hasExploit == False) & (df_pre.score < 5)]) / len(df_pre[df_pre.hasExploit == False])\n",
        "print(rec_non_ex)\n",
        "\n",
        "print(\"f-1 of exploited vulnerabilites\")\n",
        "f1_ex = (pre_ex * rec_ex) / (pre_ex + rec_ex)\n",
        "print(f1_ex)\n",
        "\n",
        "print(\"f-1 of non exploited vulnerabilites\")\n",
        "f1_non_ex = (pre_non_ex * rec_non_ex) / (pre_non_ex + rec_non_ex)\n",
        "print(f1_non_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "zOoV5fUU4BZM",
        "outputId": "269d2587-3bcf-4700-cbdc-7c7830d11611"
      },
      "outputs": [],
      "source": [
        "plot_data = df_pre.groupby(df_pre.publishedDate.dt.year).agg('count')\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
        "\n",
        "sns.barplot(\n",
        "    x=list(plot_data['hasExploit'].keys()),\n",
        "    y=list(plot_data['hasExploit'].values),\n",
        "    palette='magma'\n",
        "    )\n",
        "\n",
        "plt.title('Number of vulnerabilities on the NVD through the years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Aggregated count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00uyBxgQ4DHE",
        "outputId": "41c728bd-5dbb-4e39-b4e8-28b7a239f277"
      },
      "outputs": [],
      "source": [
        "[df_pre[(df_pre.publishedDate.dt.year < 1999)].count() / df_pre.count()][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "4BxRBKGk4E2-",
        "outputId": "410b41af-65ae-449b-f4bf-511ca8eaff87"
      },
      "outputs": [],
      "source": [
        "print(df_pre['hasExploit'].value_counts())\n",
        "\n",
        "df_ex = pd.DataFrame(df_pre['hasExploit'].value_counts().reset_index())\n",
        "plt.pie(data=df_ex,\n",
        "    x='hasExploit',\n",
        "    labels=['not exploited', 'exploited'],\n",
        "    colors=sns.color_palette('pastel'),\n",
        "    autopct='%.2f%%')\n",
        "plt.show()\n",
        "\n",
        "len_has_exploit = len(df_pre[df_pre['hasExploit'] == True])\n",
        "\n",
        "print(len_has_exploit/len(df_pre))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "vzZiLh7K4HHR",
        "outputId": "9a45119e-40c3-4aa0-e165-3484ee6c193b"
      },
      "outputs": [],
      "source": [
        "plot_data = df_pre.groupby(df_pre.publishedDate.dt.year).sum()\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
        "\n",
        "sns.barplot(\n",
        "    x=list(plot_data['hasExploit'].keys()),\n",
        "    y=list(plot_data['hasExploit'].values),\n",
        "    palette='magma'\n",
        "    )\n",
        "\n",
        "plt.title('Vulnerabilities with known exploits on the NVD through the years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Exploits')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTUir1hq4Itf",
        "outputId": "60b761bb-17c7-4904-c458-527ca95f71b3"
      },
      "outputs": [],
      "source": [
        "print('Percentage of vulnerabilites with known exploits from March 2022 from total:')\n",
        "print([\n",
        "    df_pre[\n",
        "        (df_pre.publishedDate.dt.year == 2022) & \n",
        "        (df_pre.publishedDate.dt.month > 3) & \n",
        "        (df_pre.hasExploit == 1)].count() /\n",
        "    df_pre[\n",
        "        (df_pre.publishedDate.dt.year == 2022) & \n",
        "        (df_pre.publishedDate.dt.month > 3)].count()][0][0])\n",
        "\n",
        "print('Percentage of vulnerabilites from March 2022:')\n",
        "print([\n",
        "    df_pre[\n",
        "        (df_pre.publishedDate.dt.year == 2022) & \n",
        "        (df_pre.publishedDate.dt.month > 3)].count() /\n",
        "        df_pre.count()][0][0])\n",
        "\n",
        "print('Percentage of vulnerabilites with known exploits from March 2022:')\n",
        "print([\n",
        "    df_pre[\n",
        "        (df_pre.publishedDate.dt.year == 2022) & \n",
        "        (df_pre.publishedDate.dt.month > 3) & \n",
        "        (df_pre.hasExploit == 1)].count() / \n",
        "    df_pre[\n",
        "        (df_pre.publishedDate.dt.year == 2022) & \n",
        "        (df_pre.publishedDate.dt.month > 3)].count()][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4IrcDMv4K3k",
        "outputId": "8dfe5a51-8005-47a5-c1dc-3850a2f1be72"
      },
      "outputs": [],
      "source": [
        "print('Percentage of vulnerabilites with known exploits before 2000 from total:')\n",
        "print([\n",
        "    df_pre[\n",
        "        (df_pre.publishedDate.dt.year < 2000) & \n",
        "        (df_pre.hasExploit == 1)].count() / \n",
        "        df_pre.count()][0][0])\n",
        "\n",
        "print('Percentage of vulnerabilites with known exploits before 2000:')\n",
        "print([\n",
        "    df_pre[\n",
        "        (df_pre.publishedDate.dt.year < 2000) & \n",
        "        (df_pre.hasExploit == 1)].count() / \n",
        "    df_pre[\n",
        "        (df_pre.publishedDate.dt.year < 2000)].count()][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCSGs7fN4Om-",
        "outputId": "e27df515-a8d7-4ce8-936e-12e3d435e438"
      },
      "outputs": [],
      "source": [
        "print('Sum of vulnerabilites prior to 2000 and from March of 2022:')\n",
        "print([df_pre[(df_pre.publishedDate.dt.year < 2000)].count()][0][0] + \n",
        "    [df_pre[\n",
        "        (df_pre.publishedDate.dt.year == 2022) & \n",
        "        (df_pre.publishedDate.dt.month > 3)].count()][0][0])\n",
        "\n",
        "print('Percentage of vulnerabilites prior to 2000 and from March of 2022 from total:')\n",
        "print(([df_pre[(df_pre.publishedDate.dt.year < 2000)].count()][0][0] + \n",
        "    [df_pre[\n",
        "        (df_pre.publishedDate.dt.year == 2022) & \n",
        "        (df_pre.publishedDate.dt.month > 3)].count()][0][0])/len(df_pre))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLpaZs-d4Pgo"
      },
      "outputs": [],
      "source": [
        "df_pre = df_pre.drop(df_pre[(df_pre.publishedDate.dt.year < 2000)].index)\n",
        "df_pre = df_pre.drop(df_pre[(df_pre.publishedDate.dt.year == 2022) & (df_pre.publishedDate.dt.month > 3)].index)\n",
        "df_pre.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "juLgR8VU4RHw",
        "outputId": "ed1254d9-7a44-4467-e6d4-3342e128cc0f"
      },
      "outputs": [],
      "source": [
        "print(df_pre['hasExploit'].value_counts())\n",
        "\n",
        "df_ex = pd.DataFrame(df_pre['hasExploit'].value_counts().reset_index())\n",
        "plt.pie(data=df_ex,\n",
        "    x='hasExploit',\n",
        "    labels=['not exploited', 'exploited'],\n",
        "    colors=sns.color_palette('pastel'),\n",
        "    autopct='%.2f%%')\n",
        "plt.show()\n",
        "\n",
        "len_has_exploit = len(df_pre[df_pre['hasExploit'] == True])\n",
        "\n",
        "print(len_has_exploit/len(df_pre))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxEHyQxB4TXn"
      },
      "outputs": [],
      "source": [
        "df_pre['publishedDate'] = df_pre['publishedDate'].view('int64')\n",
        "df_pre['lastModifiedDate'] = df_pre['lastModifiedDate'].view('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6maeAkH54VXL"
      },
      "outputs": [],
      "source": [
        "df_nlp = df_pre.copy()\n",
        "df_nlp.drop(columns=['assigner', 'description', 'references', 'cwes', 'score'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pprl1-B4ZQM",
        "outputId": "a3cc4335-d748-43c0-b397-8cd20f9c3813"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    token_pattern=r\"^\\S+@\\S+\\.\\S+$\",\n",
        "    smooth_idf=True,\n",
        "    max_features=150\n",
        ")\n",
        "BoW = vectorizer.fit_transform(df_pre['assigner'])\n",
        "print(BoW.shape)\n",
        "df_bow_assig = pd.DataFrame(BoW.toarray(), columns=vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rh_aH8d4a98",
        "outputId": "745ae1dd-cb66-4401-bcfd-848fd70c3362"
      },
      "outputs": [],
      "source": [
        "cwes = map((lambda x: ','.join(x)), df_pre['cwes'])\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    token_pattern=r\"[\\w+\\-]+\\w+\",\n",
        "    smooth_idf=True,\n",
        "    max_features=200\n",
        "    )\n",
        "BoW = vectorizer.fit_transform(cwes)\n",
        "print(BoW.shape)\n",
        "df_bow_cwes = pd.DataFrame(BoW.toarray(), columns=vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nIdrs2G4cYg",
        "outputId": "da788878-f6a3-41f4-d7ee-60b66c578635"
      },
      "outputs": [],
      "source": [
        "def remove_prefix(text, prefix):\n",
        "    if text.startswith(prefix):\n",
        "        return text[len(prefix):]\n",
        "    return text\n",
        "\n",
        "def find_src(refs):\n",
        "    res = ''\n",
        "    for r in refs:\n",
        "        r = remove_prefix(r, 'https://')\n",
        "        r = remove_prefix(r, 'http://')\n",
        "        r = remove_prefix(r, 'www.')\n",
        "        r = r.split('/')[0]\n",
        "        res += ' ' + ''.join(r)\n",
        "    return res\n",
        "\n",
        "refs = map(find_src, df_pre['references'])\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    token_pattern=r\"[\\w]+[.\\w]+\",\n",
        "    smooth_idf=True,\n",
        "    max_features=250\n",
        "    )\n",
        "BoW = vectorizer.fit_transform(refs)\n",
        "print(BoW.shape)\n",
        "df_bow_refs = pd.DataFrame(BoW.toarray(), columns=vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDudMK7K4feN"
      },
      "outputs": [],
      "source": [
        "# df_nlp = pd.concat([df_nlp,df_bow_desc], axis=1)\n",
        "df_nlp = pd.concat([df_nlp,df_bow_assig], axis=1)\n",
        "df_nlp = pd.concat([df_nlp,df_bow_cwes], axis=1)\n",
        "df_nlp = pd.concat([df_nlp,df_bow_refs], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "zsdNYoJJ4-zx",
        "outputId": "baed11ad-9cc7-4609-edbd-44d1d79a8d69"
      },
      "outputs": [],
      "source": [
        "most_common = dict(df_bow_refs.sum(axis=0).sort_values(ascending=False)[:25])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
        "\n",
        "sns.barplot(\n",
        "    x=list(most_common.keys()),\n",
        "    y=list(most_common.values()),\n",
        "    palette='magma_r'\n",
        "    )\n",
        "\n",
        "plt.xlabel('Websites')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "0gbPHao75CEO",
        "outputId": "ccccfb39-44d9-493c-e410-2559dbb5ad17"
      },
      "outputs": [],
      "source": [
        "most_common = dict(df_bow_cwes.sum(axis=0).sort_values(ascending=False)[:25])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
        "\n",
        "sns.barplot(\n",
        "    x=list(most_common.keys()),\n",
        "    y=list(most_common.values()),\n",
        "    palette='magma_r'\n",
        "    )\n",
        "\n",
        "plt.xlabel('CWEs')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "HEzdXnHL7-US",
        "outputId": "ce1c03fd-038a-45b2-8506-aeea4c6ba47e"
      },
      "outputs": [],
      "source": [
        "most_common = dict(df_bow_assig.sum(axis=0).sort_values(ascending=False)[:25])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
        "\n",
        "sns.barplot(\n",
        "    x=list(most_common.keys()),\n",
        "    y=list(most_common.values()),\n",
        "    palette='magma_r'\n",
        "    )\n",
        "\n",
        "plt.xlabel('References')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iT-fYZe18Dnp"
      },
      "outputs": [],
      "source": [
        "model = Doc2Vec.load(\"/content/drive/MyDrive/Uni/TFG/Code/Doc2Vec_data/descriptions_100d_100w.d2v\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdHQrn2i8NQA"
      },
      "outputs": [],
      "source": [
        "model_dvs = []\n",
        "for dv in model.docvecs.vectors_docs:\n",
        "    model_dvs.append(dv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObiR2fEa8PjD"
      },
      "outputs": [],
      "source": [
        "df_features = pd.DataFrame(model_dvs, columns=[f'd2v_{i}' for i in range(len(model_dvs[0]))])\n",
        "df_nlp = pd.concat([df_nlp, df_features], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSqBv1caBdzJ",
        "outputId": "e1a44e66-bc72-487b-e1bf-28089059502b"
      },
      "outputs": [],
      "source": [
        "df_nlp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qbrmh2y8kvP"
      },
      "outputs": [],
      "source": [
        "X = df_nlp.drop('hasExploit', axis = 1)\n",
        "y = df_nlp['hasExploit']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtwygrd0CPgT"
      },
      "outputs": [],
      "source": [
        "mutual_info = mutual_info_classif(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZQRwo9cQp3_"
      },
      "outputs": [],
      "source": [
        "mutual_info_sorted = mutual_info.copy()\n",
        "mutual_info_sorted.sort()\n",
        "\n",
        "X_mutual_info_selected = X.iloc[:, np.argsort(mutual_info)[-100:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO4tiCVKQ86q"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [20, 7]\n",
        "\n",
        "sns.barplot(\n",
        "    x=X_mutual_info_selected.columns,\n",
        "    y=mutual_info_sorted[-100:],\n",
        "    palette='magma_r'\n",
        "    )\n",
        "plt.ylim(0,0.25)\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Mutual information')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMS1jJNmRAAf"
      },
      "outputs": [],
      "source": [
        "X_mutual_info_d2v = [col for col in X_mutual_info_selected if 'd2v_' in col]\n",
        "X_mutual_info_d2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smGYmk1QIivP"
      },
      "outputs": [],
      "source": [
        "selector = SelectKBest(f_classif, k=100).fit(X, y)\n",
        "selector.fit(X, y)\n",
        "cols = selector.get_support(indices=True)\n",
        "indices = np.argsort(selector.scores_)[::-1]\n",
        "X_f_classif_selected = X.iloc[:,cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWb0KfWBImr5"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [20, 7]\n",
        "\n",
        "sns.barplot(\n",
        "    x=X.columns.values[indices[:100]],\n",
        "    y=selector.scores_[np.argsort(selector.scores_)[::-1]][:100],\n",
        "    palette='magma_r'\n",
        "    )\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('ANOVA F-value')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B8ljOWDRD-D"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_mutual_info_selected, y, test_size=0.33, stratify=y, random_state=42)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_f_classif_selected, y, test_size=0.33, stratify=y, random_state=42)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.33, stratify=y, random_state=42)\n",
        "\n",
        "df_train = pd.concat([X_train, y_train], axis=1)\n",
        "df_sample = df_train.groupby('hasExploit', group_keys=False).apply(lambda x: x.sample(frac=0.25))\n",
        "# df_sample.reset_index(inplace=True, drop=True)\n",
        "\n",
        "X_train_sample = df_sample.drop('hasExploit', axis = 1).values\n",
        "y_train_sample = df_sample['hasExploit'].values.ravel()\n",
        "\n",
        "X_train = X_train.values\n",
        "y_train = y_train.values.ravel()\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values.ravel()\n",
        "\n",
        "mm_scaler = MinMaxScaler().fit(X_train)\n",
        "X_train_mm = mm_scaler.transform(X_train)\n",
        "X_train_sample_mm = mm_scaler.transform(X_train_sample)\n",
        "X_test_mm = mm_scaler.transform(X_test)\n",
        "\n",
        "std_scaler = StandardScaler().fit(X_train)\n",
        "X_train_std = std_scaler.transform(X_train)\n",
        "X_train_sample_std = std_scaler.transform(X_train_sample)\n",
        "X_test_std = std_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-j8gZj2Rt6C"
      },
      "outputs": [],
      "source": [
        "classifiers = {\n",
        "  \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "  \"Linear Support Vector Classifier\": LinearSVC(random_state=42, max_iter=20000),\n",
        "  \"Multinomial Naive Bayes\": MultinomialNB(),\n",
        "  \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "  # \"RBF Support Vector Classifier\": SVC(kernel='rbf', random_state=42),\n",
        "}\n",
        "\n",
        "modified_classifiers = {\n",
        "  # \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'), \n",
        "  # \"Random Forest\": RandomForestClassifier(random_state=42, class_weight={0:1,1:10}),\n",
        "  # \"Gradient Boost\": GradientBoostingClassifier(random_state=42),\n",
        "  # \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=500, class_weight='balanced', n_jobs=-1),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJkDvBKhRxV9"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(name='Training score - Standard Deviation',\n",
        "                            x=train_sizes,\n",
        "                            y=train_scores_mean+train_scores_std,\n",
        "                            mode='lines',\n",
        "                            showlegend=False,\n",
        "                            marker=dict(color='green')))\n",
        "    fig.add_trace(go.Scatter(name='Training score',\n",
        "                            x=train_sizes,\n",
        "                            y=train_scores_mean,\n",
        "                            fill='tonexty',\n",
        "                            mode='lines+markers',\n",
        "                            marker=dict(color='green')))\n",
        "    fig.add_trace(go.Scatter(name='Training score + Standard Deviation',\n",
        "                            x=train_sizes,\n",
        "                            y=train_scores_mean-train_scores_std,\n",
        "                            mode='lines',\n",
        "                            fill='tonexty',\n",
        "                            showlegend=False,\n",
        "                            marker=dict(color='green')))\n",
        "    fig.add_trace(go.Scatter(x=train_sizes,\n",
        "                            y=test_scores_mean+test_scores_std,\n",
        "                            mode='lines',\n",
        "                            showlegend=False,\n",
        "                            marker=dict(color='red')))\n",
        "    fig.add_trace(go.Scatter(name='Validation Score',\n",
        "                            x=train_sizes,\n",
        "                            y=test_scores_mean,\n",
        "                            mode='lines+markers',\n",
        "                            fill='tonexty',\n",
        "                            marker=dict(color='red')))\n",
        "    fig.add_trace(go.Scatter(x=train_sizes,\n",
        "                            y=test_scores_mean-test_scores_std,\n",
        "                            mode='lines',\n",
        "                            fill='tonexty',\n",
        "                            showlegend=False,\n",
        "                            marker=dict(color='red')))\n",
        "\n",
        "    fig.update_layout(width=700,height=400,template='seaborn',title=title,\n",
        "                        margin=dict(l=60,r=0,b=0,t=40),legend=dict(orientation='h',x=0.5,y=1),\n",
        "                        xaxis=dict(title='Training examples',mirror=True,linecolor='black',linewidth=2),\n",
        "                        yaxis=dict(title='Scores',range=ylim if ylim is not None else None,\n",
        "                        mirror=True,linecolor='black',linewidth=2))\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onNd472ZR33v"
      },
      "outputs": [],
      "source": [
        "# plot_learning_curve(RandomForestClassifier(random_state=42, class_weight={0:1, 1:3}),'Random Forest', X_train, y_train, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utTrke7cR5c0"
      },
      "outputs": [],
      "source": [
        "# plot_learning_curve(RandomForestClassifier(random_state=42, n_estimators=500),'Random Forest', X_train, y_train, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x33EoQ2FR9wf"
      },
      "outputs": [],
      "source": [
        "cross_validations = []\n",
        "\n",
        "print('Cross-Validation Scores:')\n",
        "for key, classifier in classifiers.items():\n",
        "\n",
        "  if key == 'Linear Support Vector Classifier':\n",
        "    X_train_conditional = X_train_std\n",
        "  elif key == 'Multinomial Naive Bayes':\n",
        "    X_train_conditional = X_train_mm\n",
        "  else:\n",
        "    X_train_conditional = X_train\n",
        "\n",
        "  classifier.fit(X_train_conditional, y_train)\n",
        "  cross_validation = cross_validate(\n",
        "      classifier,\n",
        "      X_train_conditional,\n",
        "      y_train,\n",
        "      cv=5,\n",
        "      scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1'],\n",
        "      return_estimator=True,\n",
        "      return_train_score=True)\n",
        "  cross_validations.append(cross_validation)\n",
        "  print('-'*30)\n",
        "  print(f'{key}:')\n",
        "  print('-'*30)\n",
        "  for metric in cross_validation.keys():\n",
        "    print(f'{metric}: {cross_validation[metric]}')\n",
        "  print('-'*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbo8aF1BJOEy"
      },
      "outputs": [],
      "source": [
        "plot_learning_curve(cross_validations[0]['estimator'][4],'AdaBoost', X_train, y_train, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7i-WPLlJRW_"
      },
      "outputs": [],
      "source": [
        "plot_learning_curve(cross_validations[1]['estimator'][4],'Linear SVM', X_train_std, y_train, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA5zCD7AJTeu"
      },
      "outputs": [],
      "source": [
        "plot_learning_curve(cross_validations[2]['estimator'][4],'Multinomial Naive Bayes', X_train_std, y_train, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "856X8-kGJVyf"
      },
      "outputs": [],
      "source": [
        "plot_learning_curve(cross_validations[3]['estimator'][4],'Random Forest', X_train, y_train, n_jobs=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojyN_3hdSEsN"
      },
      "outputs": [],
      "source": [
        "model = classifiers['Random Forest']\n",
        "oversampling = SMOTE(sampling_strategy='minority')\n",
        "undersampling = RandomUnderSampler(sampling_strategy='majority')\n",
        "\n",
        "soft_oversampling = SMOTE(sampling_strategy=0.5)\n",
        "soft_undersampling = RandomUnderSampler(sampling_strategy=0.8)\n",
        "\n",
        "steps_u = [('u', undersampling), ('m', model)]\n",
        "steps_o = [('o', oversampling), ('m', model)]\n",
        "steps_comb = [('so', soft_oversampling), ('su', soft_undersampling), ('m', model)]\n",
        "\n",
        "pipeline_u = imbPipeline(steps=steps_u)\n",
        "pipeline_o = imbPipeline(steps=steps_o)\n",
        "pipeline_comb = imbPipeline(steps=steps_comb)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MkNru9aSJp7"
      },
      "outputs": [],
      "source": [
        "pipelines = {}\n",
        "for key, classifier in classifiers.items():\n",
        "  steps = [('so', soft_oversampling), ('su', soft_undersampling), ('m', classifier)]\n",
        "  pipelines[key] = imbPipeline(steps=steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0jqR0HhSMRz"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"AdaBoost\": {\"m__n_estimators\": [250]}, # [100, 250]},\n",
        "    \"Linear Support Vector Classifier\": {'m__C': [10]}, # [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
        "    \"Multinomial Naive Bayes\": {'m__alpha': [1, 2, 5, 10]},\n",
        "    \"Random Forest\": {'m__n_estimators': [100, 250], 'm__criterion':['gini', 'entropy'], 'm__max_depth':[None]},\n",
        "}\n",
        "\n",
        "gridsearchcv_scores = []\n",
        "cross_validations_grid_search = []\n",
        "best_classifiers = []\n",
        "\n",
        "for key, pipeline in pipelines.items():\n",
        "  if key == 'Linear Support Vector Classifier':\n",
        "    X_train_conditional_sampled = X_train_sample_std\n",
        "    X_train_conditional = X_train_std\n",
        "  elif key == 'Multinomial Naive Bayes':\n",
        "    X_train_conditional_sampled = X_train_sample_mm\n",
        "    X_train_conditional = X_train_mm\n",
        "  else:\n",
        "    X_train_conditional_sampled = X_train_sample\n",
        "    X_train_conditional= X_train\n",
        "\n",
        "  grid_classifier = GridSearchCV(\n",
        "      pipeline,\n",
        "      param_grid=params[key],\n",
        "      return_train_score=True,\n",
        "      scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1'],\n",
        "      refit='f1'\n",
        "  )\n",
        "\n",
        "  grid_classifier.fit(X_train_conditional_sampled, y_train_sample)\n",
        "\n",
        "  print('Finished grid search cross validation')\n",
        "\n",
        "  best_classifiers.append(grid_classifier.best_estimator_)\n",
        "  gridsearchcv_scores.append(grid_classifier.cv_results_)\n",
        "  cross_validation = cross_validate(\n",
        "        grid_classifier.best_estimator_,\n",
        "        X_train_conditional,\n",
        "        y_train,\n",
        "        cv=3,\n",
        "        scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1'],\n",
        "        return_estimator=True,\n",
        "        return_train_score=True)\n",
        "  print('-'*30)\n",
        "  print(f'{key}:')\n",
        "  print('-'*30)\n",
        "  cross_validations_grid_search.append(cross_validation)\n",
        "  for metric in cross_validation.keys():\n",
        "    print(f'{metric}: {cross_validation[metric]}')\n",
        "  print('-'*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ykr124O3TH3B"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(scores):\n",
        "  fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 12))\n",
        "  accuracies = [cv['test_accuracy'].mean() for cv in scores]\n",
        "  precisions = [cv['test_precision'].mean() for cv in scores]\n",
        "  recalls = [cv['test_recall'].mean() for cv in scores]\n",
        "  f1s = [cv['test_f1'].mean() for cv in scores]\n",
        "\n",
        "  print(accuracies)\n",
        "  print(precisions)\n",
        "  print(recalls)\n",
        "  print(f1s)\n",
        "\n",
        "  sns.barplot(ax=axs[0, 0], y=accuracies, x=list(classifiers.keys()), palette='magma_r')\n",
        "  axs[0, 0].set_title('Accuracy')\n",
        "  sns.barplot(ax=axs[0, 1], y=precisions, x=list(classifiers.keys()), palette='magma_r')\n",
        "  axs[0, 1].set_title('Precision')\n",
        "  sns.barplot(ax=axs[1, 0], y=recalls, x=list(classifiers.keys()), palette='magma_r')\n",
        "  axs[1, 0].set_title('Recall')\n",
        "  sns.barplot(ax=axs[1, 1], y=f1s, x=list(classifiers.keys()), palette='magma_r')\n",
        "  axs[1, 1].set_title('F1-score')\n",
        "\n",
        "  for ax in axs.flat:\n",
        "      ax.label_outer()\n",
        "      ax.set_xticklabels(list(classifiers.keys()), rotation=45)\n",
        "      ax.set_ylim([0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIDGXKHjTcto"
      },
      "outputs": [],
      "source": [
        "plot_metrics(cross_validations_grid_search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkQHqQJyUoRR"
      },
      "outputs": [],
      "source": [
        "ada_pred = best_classifiers[0].predict(X_train)\n",
        "linear_svm_pred = best_classifiers[1].predict(X_train_std)\n",
        "multinomial_nb_pred = best_classifiers[2].predict(X_train_mm)\n",
        "rf_pred = best_classifiers[3].predict(X_train)\n",
        "\n",
        "\n",
        "ada_fpr, ada_tpr, ada_threshold = roc_curve(y_train, ada_pred)\n",
        "lin_fpr, lin_tpr, lin_threshold = roc_curve(y_train, linear_svm_pred)\n",
        "nb_fpr, nb_tpr, nb_threshold = roc_curve(y_train, multinomial_nb_pred)\n",
        "rf_fpr, rf_tpr, rf_threshold = roc_curve(y_train, rf_pred)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(name='AdaBoost Score: {:.4f}'.format(roc_auc_score(y_train, ada_pred)),\n",
        "                         x=ada_fpr,y=ada_tpr,mode='lines'))\n",
        "fig.add_trace(go.Scatter(name='Linear Suppor Vector Score: {:.4f}'.format(roc_auc_score(y_train, linear_svm_pred)),\n",
        "                         x=lin_fpr,y=lin_tpr,mode='lines'))\n",
        "fig.add_trace(go.Scatter(name='Multinomial Naive Bayes Score: {:.4f}'.format(roc_auc_score(y_train, multinomial_nb_pred)),\n",
        "                         x=nb_fpr,y=nb_tpr,mode='lines'))\n",
        "fig.add_trace(go.Scatter(name='Random Forest Score: {:.4f}'.format(roc_auc_score(y_train, rf_pred)),\n",
        "                         x=rf_fpr,y=rf_tpr,mode='lines'))\n",
        "fig.add_trace(go.Scatter(name='AUC-ROC=0.5',x=[0,1],y=[0,1],line=dict(dash='dot'),showlegend=False))\n",
        "fig.update_layout(\n",
        "    width=700,xaxis=dict(mirror=True,linewidth=2,linecolor='black'),\n",
        "    xaxis_title='False Positive Rate',\n",
        "    yaxis_title='True Positive Rate',\n",
        "    yaxis=dict(mirror=True,linewidth=2,linecolor='black'),\n",
        "    template='seaborn',\n",
        "    legend=dict(\n",
        "        x=0.515,\n",
        "        y=0.01,\n",
        "        traceorder=\"normal\",\n",
        "        font=dict(\n",
        "            family=\"sans-serif\",\n",
        "            size=12,\n",
        "            color=\"black\"\n",
        "        ),\n",
        "        bordercolor=\"Black\",\n",
        "        borderwidth=2\n",
        "    ),\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wcWp8O7UBZ8"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_train, ada_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-izLkO-ZEcg"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_train, linear_svm_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTuTEz4rZFLw"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_train, multinomial_nb_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2QZ2roeZFlA"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_train, rf_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1jq1276I-Li"
      },
      "outputs": [],
      "source": [
        "final_pred = best_classifiers[3].predict(X_test)\n",
        "print(classification_report(y_test, final_pred, target_names=['No Exploit', 'Exploit']))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, final_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jypY2MYNAn7-"
      },
      "outputs": [],
      "source": [
        "best_classifiers[3]['m'].feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkUxbeVw-VFQ"
      },
      "outputs": [],
      "source": [
        "feature_names = X_mutual_info_selected.columns\n",
        "mdi_importances = pd.Series(\n",
        "    best_classifiers[3]['m'].feature_importances_, index=feature_names\n",
        ").sort_values(ascending=False)[:25]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,10))\n",
        "sns.barplot(\n",
        "          x=mdi_importances.values,\n",
        "          y=mdi_importances.index,\n",
        "          palette='magma_r'\n",
        "          )\n",
        "ax.set(xlabel='features', ylabel='')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Complete.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
